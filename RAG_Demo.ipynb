{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed42c56",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Extraction\" data-toc-modified-id=\"Extraction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Extraction</a></span></li><li><span><a href=\"#Loading\" data-toc-modified-id=\"Loading-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Loading</a></span></li><li><span><a href=\"#Splitting\" data-toc-modified-id=\"Splitting-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Splitting</a></span></li><li><span><a href=\"#Storing\" data-toc-modified-id=\"Storing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Storing</a></span></li><li><span><a href=\"#Retrieval\" data-toc-modified-id=\"Retrieval-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Retrieval</a></span></li><li><span><a href=\"#Question-Answering\" data-toc-modified-id=\"Question-Answering-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Question Answering</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "154c5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain openai chromadb python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aee5b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set env var OPENAI_API_KEY or load from a .env file\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d79f51",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c58f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_urls import crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35884d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://python.langchain.com/docs/get_started/introduction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "689013b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://python.langchain.com/docs/get_started/introduction\n",
      "https://python.langchain.com/docs/get_started/installation\n",
      "https://python.langchain.com/docs/community\n",
      "https://python.langchain.com/docs/additional_resources/dependents\n",
      "https://python.langchain.com/docs/additional_resources/tutorials\n",
      "https://python.langchain.com/docs/use_cases\n",
      "https://python.langchain.com/docs/guides\n",
      "https://python.langchain.com/docs/guides/evaluation\n",
      "https://python.langchain.com/docs/guides/evaluation/trajectory\n",
      "https://python.langchain.com/docs/guides/evaluation/trajectory/custom\n"
     ]
    }
   ],
   "source": [
    "urls = crawl(base_url, max_urls=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e4590c",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c9dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac97480",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b52febb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4927cc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Guides | ü¶úÔ∏èüîó Langchain\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKGet startedIntroductionInstallationQuickstartModulesModel I/‚ÄãORetrievalChainsMemoryAgentsCallbacksModulesLangChain Expression LanguageGuidesAdaptersDebuggingDeploymentEvaluationFallbacksLangSmithRun LLMs locallyModel comparisonPrivacyPydantic compatibilitySafetyAdditional resourcesCommunity navigatorGuidesGuidesDesign guides for key parts of the development processüóÉÔ∏è Adapters1 itemsüìÑÔ∏è DebuggingIf you're building with LLMs, at some point something will break, and you'll need to debug. A model call will fail, or the model output will be misformatted, or there will be some nested model calls and it won't be clear where along the way an incorrect output was created.üóÉÔ∏è Deployment1 itemsüóÉÔ∏è Evaluation4 itemsüìÑÔ∏è FallbacksWhen working with language models, you may often encounter issues from the underlying APIs, whether these be rate limiting or downtime. Therefore, as you go to move your LLM applications into production it becomes more and more important to safe guard against these. That's why we've introduced the concept of fallbacks.üóÉÔ∏è LangSmith1 itemsüìÑÔ∏è Run LLMs locallyUse caseüìÑÔ∏è Model comparisonConstructing your language model application will likely involved choosing between many different options of prompts, models, and even chains to use. When doing so, you will want to compare these different options on different inputs in an easy, flexible, and intuitive way.üóÉÔ∏è Privacy1 itemsüìÑÔ∏è Pydantic compatibility- Pydantic v2 was released in June, 2023 (https://docs.pydantic.dev/2.0/blog/pydantic-v2-final/)üóÉÔ∏è Safety5 itemsPreviousLangChain Expression Language (LCEL)NextOpenAI AdapterCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[6].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad45ae",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bbbf01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5997d30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e3c47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7f7c933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "003f0354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the loopü¶ú Contribute to LangChainLangChain is the product of over 5,000+ contributions by 1,500+ contributors, and there is **still** so much to do together. Here are some ways to get involved:Open a pull request: We‚Äôd appreciate all forms of contributions‚Äìnew features, infrastructure improvements, better documentation, bug fixes, etc. If you have an improvement or an idea, we‚Äôd love to work on it with you.Read our contributor guidelines: We ask contributors to follow a¬†\"fork and pull request\"¬†workflow, run a few local checks for formatting, linting, and testing before submitting, and follow certain documentation and testing conventions.First time contributor? Try one of these PRs with the ‚Äúgood first issue‚Äù tag.Become an expert: Our experts help the community by answering product questions in Discord. If that‚Äôs a role you‚Äôd like to play, we‚Äôd be so grateful! (And we have some special experts-only goodies/perks we can tell you more about). Send us an email to introduce yourself at\n"
     ]
    }
   ],
   "source": [
    "print(all_splits[10].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426f6e9d",
   "metadata": {},
   "source": [
    "# Storing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bad6896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20a80385",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=all_splits, \n",
    "                                    embedding=OpenAIEmbeddings(), \n",
    "                                    persist_directory='langchain_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6075524d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore._collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fd210",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76ceb7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c3e4846",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f5ff51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "514ff572",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectorstore.as_retriever(),\n",
    "                                       return_source_documents=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72389d83",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da431a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is langchain framework?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "862ca825",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "641b48ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework for developing applications powered by language models. It provides components and off-the-shelf chains that make it easy to work with language models and build context-aware applications. The framework allows applications to connect language models to various sources of context, reason based on provided context, and construct sequences of calls. It also offers modules for model I/O, retrieval, chains, agents, memory, and callbacks. LangChain is part of a larger ecosystem of tools and has a community of developers and resources for support and learning.\n"
     ]
    }
   ],
   "source": [
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f6cee4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='are using the rest of the LangChain framework or notOff-the-shelf chains: a structured assembly of components for accomplishing specific higher-level tasksOff-the-shelf chains make it easy to get started. For complex applications, components make it easy to customize existing chains and build new ones.Get started\\u200bHere‚Äôs how to install LangChain, set up your environment, and start building.We recommend following our Quickstart guide to familiarize yourself with the framework by building your first LangChain application.Note: These docs are for the LangChain Python package. For documentation on LangChain.js, the JS/TS version, head here.Modules\\u200bLangChain provides standard, extendable interfaces and external integrations for the following modules, listed from least to most complex:Model I/O\\u200bInterface with language modelsRetrieval\\u200bInterface with application-specific dataChains\\u200bConstruct sequences of callsAgents\\u200bLet chains choose which tools to use given high-level directivesMemory\\u200bPersist', metadata={'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en', 'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ü¶úÔ∏èüîó Langchain'}),\n",
       " Document(page_content='Skip to main contentü¶úÔ∏èüîó LangChainDocsUse casesIntegrationsAPILangSmithJS/TS DocsCTRLKGet startedIntroductionInstallationQuickstartModulesModel I/\\u200bORetrievalChainsMemoryAgentsCallbacksModulesLangChain Expression LanguageGuidesAdditional resourcesCommunity navigatorGet startedIntroductionOn this pageIntroductionLangChain is a framework for developing applications powered by language models. It enables applications that:Are context-aware: connect a language model to sources of context (prompt instructions, few shot examples, content to ground its response in, etc.)Reason: rely on a language model to reason (about how to answer based on provided context, what actions to take, etc.)The main value props of LangChain are:Components: abstractions for working with language models, along with a collection of implementations for each abstraction. Components are modular and easy-to-use, whether you are using the rest of the LangChain framework or notOff-the-shelf chains: a structured assembly of', metadata={'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en', 'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ü¶úÔ∏èüîó Langchain'}),\n",
       " Document(page_content='of callsAgents\\u200bLet chains choose which tools to use given high-level directivesMemory\\u200bPersist application state between runs of a chainCallbacks\\u200bLog and stream intermediate steps of any chainExamples, ecosystem, and resources\\u200bUse cases\\u200bWalkthroughs and best-practices for common end-to-end use cases, like:Document question answeringChatbotsAnalyzing structured dataand much more...Guides\\u200bLearn best practices for developing with LangChain.Ecosystem\\u200bLangChain is part of a rich ecosystem of tools that integrate with our framework and build on top of it. Check out our growing list of integrations and dependent repos.Additional resources\\u200bOur community is full of prolific developers, creative builders, and fantastic teachers. Check out YouTube tutorials for great tutorials from folks in the community, and Gallery for a list of awesome LangChain projects, compiled by the folks at KyroLabs.Community\\u200bHead to the Community navigator to find places to ask questions, share feedback, meet other', metadata={'description': 'LangChain is a framework for developing applications powered by language models. It enables applications that:', 'language': 'en', 'source': 'https://python.langchain.com/docs/get_started/introduction', 'title': 'Introduction | ü¶úÔ∏èüîó Langchain'}),\n",
       " Document(page_content='Evaluation | ü¶úÔ∏èüîó Langchain', metadata={'description': \"Building applications with language models involves many moving parts. One of the most critical components is ensuring that the outcomes produced by your models are reliable and useful across a broad array of inputs, and that they work well with your application's other software components. Ensuring reliability usually boils down to some combination of application design, testing & evaluation, and runtime checks.\", 'language': 'en', 'source': 'https://python.langchain.com/docs/guides/evaluation', 'title': 'Evaluation | ü¶úÔ∏èüîó Langchain'})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['source_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea3a0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "11.3333px",
    "width": "165.99px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
